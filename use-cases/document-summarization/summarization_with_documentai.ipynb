{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e",
    "tags": []
   },
   "source": [
    "# Summarization with Large Documents using Document AI and PaLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Text summarization is the process of creating a shorter version of a text document while still preserving the most important information. This can be useful for a variety of purposes, such as quickly skimming a long document, getting the gist of an article, or sharing a summary with others.\n",
    "\n",
    "Although summarizing a short paragraph is a non-trivial task, there are a few challenges to overcome if you want to summarize a large document, such as a PDF file with multiple pages.\n",
    "\n",
    "[Document AI](https://cloud.google.com/document-ai) provides a scalable and managed way to extract data from documents using AI. In this notebook, you will use the [Document OCR processor](https://cloud.google.com/document-ai/docs/document-ocr), which is a pre-trained model that will extract text and layout information from document files. Document AI provides an API endpoint to access the models, so developers don't have to build and maintain their own models and serving infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook we will show how you can do the following:\n",
    "1. Extract text from PDF documents using the Document AI OCR processor.\n",
    "1. Use a MapReduce method to chunk the document text.\n",
    "1. Use PaLM `text-bison@001` model to generate summaries of the extracted text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j1gvi3jqG6U"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI PaLM APIs offered by Generative AI studio\n",
    "* Document AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "Learn about [Document AI pricing](https://cloud.google.com/document-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### SKIP: Install Vertex AI SDK & Other dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip pip install for hackathon since genai conda env has all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYACuZHAF3DQ",
    "outputId": "fe7c7dd2-3736-40cc-a279-7e335e0b0a2c"
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade google-cloud-aiplatform==1.28.1 google-cloud-documentai==2.17.0 backoff==2.2.1  --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Hsqwn4hkLKE",
    "outputId": "85ae3d9f-cd86-4eef-febd-1d26a721fb4b"
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "## Document AI\n",
    "\n",
    "The following [limits](https://cloud.google.com/document-ai/quotas) apply for online processing with the Document OCR processor.\n",
    "\n",
    "| Limit               | Value  |\n",
    "| :------------------ |------: |\n",
    "| Maximum file size   | 20 MB  |\n",
    "| Maximum pages       | 15     |\n",
    "\n",
    "For documents that don't meet these limits, you can use [batch processing](https://cloud.google.com/document-ai/docs/send-request#batch-process) to extract the document text. (Not covered in this notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZkLDRTjTcfm"
   },
   "source": [
    "### Preparing data files\n",
    "\n",
    "To begin, you will need to download PDFs for the summarizing tasks below.\n",
    "For this notebook, you will be using Alphabet earnings report PDFs hosted in a public Google Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-IWo-lb-gbn",
    "outputId": "b12cd23e-633b-42fa-c872-b9c7ab96f945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://wmt-aug23-vertexgenai-workshop-data/docai/20230203_alphabet_10K-pages-1-14-compressed.pdf...\n",
      "Copying gs://wmt-aug23-vertexgenai-workshop-data/docai/20230426_alphabet_10Q-pages-1-14.pdf...\n",
      "Copying gs://wmt-aug23-vertexgenai-workshop-data/docai/documents_20220202_alphabet_10K.pdf...\n",
      "/ [3/3 files][  5.0 MiB/  5.0 MiB] 100% Done                                    \n",
      "Operation completed over 3 objects/5.0 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Copying the files from the GCS bucket to local storage\n",
    "!gsutil -m cp -r gs://wmt-aug23-vertexgenai-workshop-data/docai ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxmWYA05o4jj"
   },
   "source": [
    "### Create Document AI OCR Processor\n",
    "\n",
    "A [Document AI processor](https://cloud.google.com/document-ai/docs/overview#dai-processors) is an interface between a document file and a machine learning model that performs document processing actions. They can be used to classify, split, parse, or analyze a document. Each Google Cloud project needs to create its own processor instances.\n",
    "\n",
    "There are two types of Document AI processors:\n",
    "\n",
    "* Pre-trained processors: These processors are pre-trained on a large dataset of documents and can be used to perform common document processing tasks, such as Optical Character Recognition (OCR), form parsing, and entity extraction.\n",
    "* Custom processors: These processors can be trained on your own dataset of documents to perform specific tasks that are not covered by the pre-trained processors.\n",
    "\n",
    "Refer to [Full processor and detail list](https://cloud.google.com/document-ai/docs/processors-list) for all supported processors.\n",
    "\n",
    "Processors take a PDF or image file as input and output the data in the [`Document`](https://cloud.google.com/document-ai/docs/reference/rest/v1/Document) format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9URyhLDo4jk"
   },
   "source": [
    "### Create a processor\n",
    "\n",
    "Run this code only once to create the processor. You cannot create multiple processors with the same display name. If you receive an error, change the name of the processor and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Cloud Document AI API has not been used in project wmt-7fbls2a91f025anb93e025b02g before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"documentai.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/wmt-7fbls2a91f025anb93e025b02g\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/genai/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/envs/genai/lib/python3.10/site-packages/grpc/_channel.py:1161\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1155\u001b[0m (\n\u001b[1;32m   1156\u001b[0m     state,\n\u001b[1;32m   1157\u001b[0m     call,\n\u001b[1;32m   1158\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1159\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1160\u001b[0m )\n\u001b[0;32m-> 1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/genai/lib/python3.10/site-packages/grpc/_channel.py:1004\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Cloud Document AI API has not been used in project wmt-7fbls2a91f025anb93e025b02g before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:199.36.153.8:443 {created_time:\"2023-08-21T09:21:06.43399498+00:00\", grpc_status:7, grpc_message:\"Cloud Document AI API has not been used in project wmt-7fbls2a91f025anb93e025b02g before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mcreate_processor(\n\u001b[1;32m     29\u001b[0m         parent\u001b[38;5;241m=\u001b[39mparent,\n\u001b[1;32m     30\u001b[0m         processor\u001b[38;5;241m=\u001b[39mdocumentai\u001b[38;5;241m.\u001b[39mProcessor(\n\u001b[1;32m     31\u001b[0m             display_name\u001b[38;5;241m=\u001b[39mprocessor_display_name, type_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCR_PROCESSOR\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m         ),\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     processor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_display_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated Processor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessor\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AlreadyExists \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m, in \u001b[0;36mcreate_processor\u001b[0;34m(project_id, location, processor_display_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m parent \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcommon_location_path(project_id, location)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create a processor\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocumentai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor_display_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOCR_PROCESSOR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/documentai_v1/services/document_processor_service/client.py:2234\u001b[0m, in \u001b[0;36mDocumentProcessorServiceClient.create_processor\u001b[0;34m(self, request, parent, processor, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2229\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   2230\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mparent),)),\n\u001b[1;32m   2231\u001b[0m )\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2234\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/envs/genai/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/genai/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Cloud Document AI API has not been used in project wmt-7fbls2a91f025anb93e025b02g before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/documentai.googleapis.com/overview?project=wmt-7fbls2a91f025anb93e025b02g\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"documentai.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/wmt-7fbls2a91f025anb93e025b02g\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.exceptions import AlreadyExists\n",
    "from google.cloud import documentai\n",
    "\n",
    "# TODO(developer): Edit these variables before running the code.\n",
    "project_id = \"wmt-7fbls2a91f025anb93e025b02g\"\n",
    "\n",
    "# See https://cloud.google.com/document-ai/docs/regions for all options.\n",
    "location = \"us\"\n",
    "\n",
    "# Must be unique per project, e.g.: \"My Processor\"\n",
    "processor_display_name = \"Test\"\n",
    "\n",
    "# You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "client_options = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "\n",
    "def create_processor(\n",
    "    project_id: str, location: str, processor_display_name: str\n",
    ") -> documentai.Processor:\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the location\n",
    "    # e.g.: projects/project_id/locations/location\n",
    "    parent = client.common_location_path(project_id, location)\n",
    "\n",
    "    # Create a processor\n",
    "    return client.create_processor(\n",
    "        parent=parent,\n",
    "        processor=documentai.Processor(\n",
    "            display_name=processor_display_name, type_=\"OCR_PROCESSOR\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    processor = create_processor(project_id, location, processor_display_name)\n",
    "    print(f\"Created Processor {processor.name}\")\n",
    "except AlreadyExists as e:\n",
    "    print(\n",
    "        f\"Processor already exits, change the processor name and rerun this code. {e.message}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkK74RRio4jk",
    "tags": []
   },
   "source": [
    "### Process the documents\n",
    "\n",
    "Process document takes the processor name and file path of the document and extracts the text from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7bE7ZGtlcxv"
   },
   "outputs": [],
   "source": [
    "def process_document(\n",
    "    processor_name: str,\n",
    "    file_path: str,\n",
    ") -> documentai.Document:\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Load Binary Data into Document AI RawDocument Object\n",
    "    raw_document = documentai.RawDocument(\n",
    "        content=image_content, mime_type=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(name=processor_name, raw_document=raw_document)\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usKPLAna5mLd"
   },
   "source": [
    "#### Create data chunks\n",
    "\n",
    "LLMs produce the best results when summarizing documents if the input data is broken up into small \"chunks\" before being added to the prompt.\n",
    "\n",
    "The best chunk size depends on the size of the documents. It is a good idea to experiment with different chunk sizes to see what works best for your specific dataset and application. For the provided documents, we are taking `5000` as a `chunk_value`. You should experiment with other values as well and see how it affects your summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDf7Zw3SGuyW",
    "outputId": "d39f587e-d416-488d-8c44-e93cd186f926"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import textwrap\n",
    "from typing import Dict, List\n",
    "\n",
    "# If you already have a Document AI Processor in your project, assign the full processor resource name here.\n",
    "processor_name = processor.name\n",
    "chunk_size = 5000\n",
    "extracted_data: List[Dict] = []\n",
    "\n",
    "# Loop through each PDF file in the \"docai\" directory.\n",
    "for path in glob.glob(\"docai/*.pdf\"):\n",
    "    # Extract the file name and type from the path.\n",
    "    file_name, file_type = os.path.splitext(path)\n",
    "\n",
    "    print(f\"Processing {file_name}\")\n",
    "\n",
    "    # Process the document.\n",
    "    document = process_document(processor_name, file_path=path)\n",
    "\n",
    "    if document:\n",
    "        # Split the text into chunks of the specified size.\n",
    "        document_chunks = textwrap.wrap(text=document.text, width=chunk_size)\n",
    "\n",
    "        # Loop through each chunk and create a dictionary with metadata and content.\n",
    "        for chunk_number, chunk_content in enumerate(document_chunks, start=1):\n",
    "            # Append the chunk information to the extracted_data list.\n",
    "            extracted_data.append(\n",
    "                {\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_type\": file_type,\n",
    "                    \"chunk_number\": chunk_number,\n",
    "                    \"content\": chunk_content,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj7KMupOPUX-"
   },
   "source": [
    "## Summarization using the [PaLM](https://ai.google/discover/palm2/) Model\n",
    "\n",
    "You have just used Document AI to extract text from PDF files.\n",
    "\n",
    "In the next section, you will summarize the extracted text using the PaLM model with Vertex AI.\n",
    "In order to summarize the text, You can use MapReduce to chunk the text to fit the prompt size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, run the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YRKSFYOqSH4"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3edk4BiDkQ4"
   },
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKzpNLuzDeC4"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import backoff\n",
    "\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "\n",
    "# This decorator is used to handle exceptions and apply exponential backoff in case of ResourceExhausted errors.\n",
    "# It means the function will be retried with increasing time intervals in case of this specific exception.\n",
    "@backoff.on_exception(backoff.expo, ResourceExhausted, max_time=10)\n",
    "def text_generation_model_with_backoff(**kwargs):\n",
    "    \"\"\"\n",
    "    :param **kwargs: Keyword arguments for the prediction.\n",
    "    :return: The generated text.\n",
    "    \"\"\"\n",
    "    # Calls the generation_model's 'predict' method with the provided keyword arguments (**kwargs)\n",
    "    # and then accesses the 'text' attribute to get the generated text.\n",
    "    return generation_model.predict(**kwargs).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM3V1JARZ9-k",
    "tags": []
   },
   "source": [
    "## MapReduce\n",
    "\n",
    "MapReduce is a very effective approach for processing large datasets because it is scalable and efficient. It can be used to process datasets that are too large to be processed on a single machine.\n",
    "\n",
    "Using this approach we will first split the large data into chunks, then running a prompt on each chunk of text. For summarization tasks, the output from the initial prompt would be a summary of that chunk. Once all the initial outputs have been generated, a different prompt is run to combine them. This can be more effective for large datasets.\n",
    "\n",
    "This consists of two main steps, map and reduce:\n",
    "\n",
    "- The map step will split the dataset into chunks and run a prompt on each chunk of text. The output from the prompt is a summary of that chunk.\n",
    "\n",
    "- The reduce step combines the summaries from all the chunks into a single summary.\n",
    "\n",
    "Here are some pros and cons of using MapReduce method for summarization:\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Can summarize a large document\n",
    "- Can work well with parallel processing as the processes to summarize pages are independent to each other.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Multiple calls to the model is needed\n",
    "- As the pages are summarized individually, the context between the pages could be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo5NkotOJs3Y"
   },
   "source": [
    "#### Map step\n",
    "\n",
    "In this section, you will use the model to summarize each chunk of text individually using the initial prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT6brl-VCd8l"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Write a concise summary of the following text delimited by triple backquotes.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "# Create an empty list to store the summaries\n",
    "initial_summary: List[str] = []\n",
    "\n",
    "# Iterate over the pages and generate a summary for each page\n",
    "for individual_chunk in extracted_data:\n",
    "    # Create a prompt for the model using the extracted text and a prompt template\n",
    "    prompt = prompt_template.format(text=individual_chunk[\"content\"].strip())\n",
    "\n",
    "    # Generate a summary using the model and the prompt\n",
    "    summary = text_generation_model_with_backoff(prompt=prompt, max_output_tokens=1024)\n",
    "\n",
    "    # Append the summary to the list of summaries\n",
    "    initial_summary.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ3cOxWOJs3d"
   },
   "source": [
    "Take a look at the first few summaries of from the initial Map phase. These are the summaries of each individual chunk of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-YHPaQbDH5t",
    "outputId": "f40d98e5-02cf-4278-8b6f-597cc3721f52"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(initial_summary[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HczirNnJs3d"
   },
   "source": [
    "#### Reduce step\n",
    "\n",
    "Here you will create a reduce function that concatenates the summaries from the inital summarization step (Map step) and use the final prompt template to create a summary of the initial summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MF4JryiDTIK",
    "outputId": "7c3ccd01-5da8-4001-985f-153d7100aaac"
   },
   "outputs": [],
   "source": [
    "# Concatenate the summaries from the inital step\n",
    "concat_summary = \"\\n\".join(initial_summary)\n",
    "\n",
    "# Create a prompt for the model using the concatenated text and a prompt template\n",
    "prompt = prompt_template.format(text=concat_summary)\n",
    "\n",
    "# Generate a summary using the model and the prompt\n",
    "summary = text_generation_model_with_backoff(prompt=prompt, max_output_tokens=34)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLFuRGrtN-9l"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. How to use Document AI to extract text from these PDFs.\n",
    "2. How to use MapReduce to efficiently process large amounts of text data.\n",
    "3. How to summarize the text extracted from the PDFs using the PaLM `text-bison@001` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhR1vTtpXj1q"
   },
   "source": [
    "## Clean Up\n",
    "\n",
    "If you no longer need the Document AI processor, you can delete it using the following code.\n",
    "\n",
    "Alternatively, you can use the Cloud Console to delete the processor as outlined in [Creating and managing processors > Delete a processor](https://cloud.google.com/document-ai/docs/create-processor#documentai_delete_processor-web)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "EuTdzGhbe9C3",
    "outputId": "4d1a1fa6-d638-4f76-a114-6463e1fa1938"
   },
   "outputs": [],
   "source": [
    "def delete_processor(processor_name: str) -> None:\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # Delete a processor\n",
    "    operation = client.delete_processor(name=processor_name)\n",
    "    # Print operation details\n",
    "    print(operation.operation.name)\n",
    "    # Wait for operation to complete\n",
    "    operation.result()\n",
    "\n",
    "\n",
    "delete_processor(delete_processor, processor_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-genai-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3 (genai)",
   "language": "python",
   "name": "conda-env-genai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
