{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Create Vertex AI Matching Engine index\n",
    "![ ](https://www.google-analytics.com/collect?v=2&tid=G-L6X3ECH596&cid=1&en=page_view&sid=1&dt=sdk_matching_engine_for_indexing.ipynb&dl=notebooks%2Fofficial%2Fmatching_engine%2Fsdk_matching_engine_for_indexing.ipynb)\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "      <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0a74aaf1481"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This example demonstrates how to use the Vertex AI ANN Service. It is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
    "\n",
    "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34a4b245e795"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you learn how to create Approximate Nearest Neighbor (ANN) Index, query against indexes, and validate the performance of the index. \n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "- `Vertex AI Matching Engine`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "* Create ANN Index and Brute Force Index\n",
    "* Create an IndexEndpoint with Private Service Connect (PSC)\n",
    "* Deploy ANN Index and Brute Force Index\n",
    "* Perform online query\n",
    "* Compute recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [GloVe dataset](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "\"GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workbench Instance with Conda Env as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Vertex Workbench Instance [here](https://console.cloud.google.com/vertex-ai/workbench/instances/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new conda environment to use as a jupyter kernel\n",
    "\n",
    "Run the following commands in the terminal of your Vertex Workbench Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new conda environment with Python 3.10 and ipykernel\n",
    "```bash\n",
    "CONDA_ENV_NAME=\"vme\"\n",
    "conda create -n $CONDA_ENV_NAME python=3.10 ipykernel\n",
    "```\n",
    "2. Change the display name of the jupyter kernel to Python 3 (env_name)\n",
    "```bash\n",
    "mv /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json /tmp/temp.json && jq -r '.display_name |= \"Python 3 ('$CONDA_ENV_NAME')\"' /tmp/temp.json > /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json && rm /tmp/temp.json\n",
    "```\n",
    "3. Deactivate conda environment\n",
    "```bash\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your new jupyter kernel for this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0f1bea346db"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Cloud Storage, BigQuery and Vertex AI SDKs for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irSMQn6gZ19l"
   },
   "source": [
    "Install the `h5py` to prepare sample dataset, and the `grpcio-tools` for querying against the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dfbccc635a17",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/envs/genai/lib/python3.10/site-packages (1.30.1)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/envs/genai/lib/python3.10/site-packages (2.10.0)\n",
      "Collecting grpcio-tools\n",
      "  Obtaining dependency information for grpcio-tools from https://files.pythonhosted.org/packages/00/8b/903898fcaf31f67180061983f6bf54027bc85ffb6f7b202f8263388fc2ae/grpcio_tools-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio_tools-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting h5py\n",
      "  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/0d/7a/e55589e4093cca1934db5e99644c1c2424a9b3aac104b7f6176605a5eeb7/h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.11.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.24.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.3)\n",
      "Requirement already satisfied: shapely<2.0.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-storage) (2.22.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: grpcio>=1.57.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from grpcio-tools) (1.57.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/genai/lib/python3.10/site-packages (from grpcio-tools) (68.0.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/genai/lib/python3.10/site-packages (from h5py) (1.25.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.57.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/genai/lib/python3.10/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/genai/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/genai/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/genai/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/envs/genai/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n",
      "Downloading grpcio_tools-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py, grpcio-tools\n",
      "Successfully installed grpcio-tools-1.57.0 h5py-3.9.0\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        grpcio-tools \\\n",
    "                        h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd28c9e4f067"
   },
   "source": [
    "## Before you begin\n",
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "80c0215f05a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"wmt-7fbls2a91f025anb93e025b02g\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! echo Y | gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f4512bf63b3"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "474be5183c27"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "949271bfebe3"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b65b4ce80d9a"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "985cdbfe7372"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fbc9cd30cc4b"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79efab26ad02"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a336a05c6149"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c0a44fa330f"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5de53b31bf1"
   },
   "source": [
    "## Make sure the following cells are run from inside the VPC network that you created in the previous step.\n",
    "\n",
    "* **WARNING:** The MatchingIndexEndpoint.match method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
    "  * **In the same region as where your ANN service is deployed** (for example, if you set `REGION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
    "  * If you run it in the colab or a Vertex AI Workbench notebook instance in a different VPC network or region, \"Create Online Queries\" section will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://wmt-aug23-vertexgenai-workshop-data/matching-engine\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://embeddings-for-kroger/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR6Wwv-hCCN-"
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "The GloVe dataset consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" split, and a \"test\" split.\n",
    "We will create a vector search index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the vector search index.\n",
    "\n",
    "**Note:** While the data split uses the term \"train\", these are pre-trained embeddings and therefore are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with machine learning terminology.\n",
    "\n",
    "Download the GloVe dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9wzS85TeB9dG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://wmt-aug23-vertexgenai-workshop-data/matching-engine/data/glove-100-angular.hdf5...\n",
      "- [1/1 files][462.9 MiB/462.9 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/462.9 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp gs://wmt-aug23-vertexgenai-workshop-data/matching-engine/data/glove-100-angular.hdf5 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fAO9CMoCNtq"
   },
   "source": [
    "Read the data into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lZ3JQTS6CN-3"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# The number of nearest neighbors to be retrieved from database for each query.\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
    "train = h5[\"train\"]\n",
    "test = h5[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pE6bBBo7GjJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11333  ,  0.48402  ,  0.090771 , -0.22439  ,  0.034206 ,\n",
       "       -0.55831  ,  0.041849 , -0.53573  ,  0.18809  , -0.58722  ,\n",
       "        0.015313 , -0.014555 ,  0.80842  , -0.038519 ,  0.75348  ,\n",
       "        0.70502  , -0.17863  ,  0.3222   ,  0.67575  ,  0.67198  ,\n",
       "        0.26044  ,  0.4187   , -0.34122  ,  0.2286   , -0.53529  ,\n",
       "        1.2582   , -0.091543 ,  0.19716  , -0.037454 , -0.3336   ,\n",
       "        0.31399  ,  0.36488  ,  0.71263  ,  0.1307   , -0.24654  ,\n",
       "       -0.52445  , -0.036091 ,  0.55068  ,  0.10017  ,  0.48095  ,\n",
       "        0.71104  , -0.053462 ,  0.22325  ,  0.30917  , -0.39926  ,\n",
       "        0.036634 , -0.35431  , -0.42795  ,  0.46444  ,  0.25586  ,\n",
       "        0.68257  , -0.20821  ,  0.38433  ,  0.055773 , -0.2539   ,\n",
       "       -0.20804  ,  0.52522  , -0.11399  , -0.3253   , -0.44104  ,\n",
       "        0.17528  ,  0.62255  ,  0.50237  , -0.7607   , -0.071786 ,\n",
       "        0.0080131, -0.13286  ,  0.50097  ,  0.18824  , -0.54722  ,\n",
       "       -0.42664  ,  0.4292   ,  0.14877  , -0.0072514, -0.16484  ,\n",
       "       -0.059798 ,  0.9895   , -0.61738  ,  0.054169 ,  0.48424  ,\n",
       "       -0.35084  , -0.27053  ,  0.37829  ,  0.11503  , -0.39613  ,\n",
       "        0.24266  ,  0.39147  , -0.075256 ,  0.65093  , -0.20822  ,\n",
       "       -0.17456  ,  0.53571  , -0.16537  ,  0.13582  , -0.56016  ,\n",
       "        0.016964 ,  0.1277   ,  0.94071  , -0.22608  , -0.021106 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQIQSyF9GtSv"
   },
   "source": [
    "#### Save the train split in JSONL format.\n",
    "\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
    "\n",
    "Additionally, to demonstrate the filtering functionality, the `restricts` key is set such that each embedding has a different `class`, `even` or `odd`. These are used during the later matching step to filter for results.\n",
    "See additional information of filtering here: https://cloud.google.com/vertex-ai/docs/matching-engine/filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "57fe2ce4b50f"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"glove100.json\", \"w\") as f:\n",
    "    embeddings_formatted = [\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"id\": str(index),\n",
    "                \"embedding\": [str(value) for value in embedding],\n",
    "                \"restricts\": [\n",
    "                    {\n",
    "                        \"namespace\": \"class\",\n",
    "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "        for index, embedding in enumerate(train)\n",
    "    ]\n",
    "    f.writelines(embeddings_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "Upload the training data to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine_demo/initial/\"\n",
    "! gsutil -m cp glove100.json {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "## Create Indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhIBCQ7dDSbW"
   },
   "source": [
    "### Create ANN Index (for Production Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qiIg9b5zJLi1"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 100\n",
    "DISPLAY_NAME = \"batch_glove_100_1\"\n",
    "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svLYiDf0OD2G"
   },
   "source": [
    "Create the ANN index configuration:\n",
    "\n",
    "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = aiplatform_v1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeAhConfig = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=7),\n",
    "    }\n",
    ")\n",
    "\n",
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "        \"shardSize\": struct_pb2.Value(string_value=\"SHARD_SIZE_SMALL\")\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME,\n",
    "    \"description\": \"Glove 100 ANN index - batch\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.BATCH_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/896267025569/locations/us-central1/indexes/7485114522085097472'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME=\"7665258507179917312\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f1a9fbecabb"
   },
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1ddb70647d98"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsqZuyoA1SG"
   },
   "source": [
    "### Create Brute Force Index (for Ground Truth)\n",
    "\n",
    "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
    "\n",
    "Create the brute force index configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"bruteForceConfig\": struct_pb2.Value(struct_value={})}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME_BRUTE_FORCE,\n",
    "    \"description\": \"Glove 100 index (brute force) - batch\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.BATCH_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m INDEX_BRUTE_FORCE_RESOURCE_NAME \u001b[38;5;241m=\u001b[39m \u001b[43mann_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m()\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m      2\u001b[0m INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_BRUTE_FORCE_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = \"3242512566869557248\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3242512566869557248'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "865fcad494d7"
   },
   "outputs": [],
   "source": [
    "brute_force_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This takes 20-30 minutes - here's some reading on what it is doing\n",
    "#### Note on the advantages of the algorithm\n",
    "\n",
    "[link](https://arxiv.org/pdf/1908.10396.pdf)\n",
    "\n",
    "```However, it is easy to see that not all pairs of (x, q) are equally important. The approximation error on the pairs which have a high inner product is far more important since they are likely to be among the top ranked pairs and can greatly affect the search result, while for the pairs whose inner product is low the approximation error matters much less. In other words, for a given datapoint x, we should quantize it with a bigger focus on its error with those queries which have high inner product with x. See Figure 1 for the illustration.```\n",
    "\n",
    "\n",
    "![](img/algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other quick notes on ME while we wait for deployment\n",
    "\n",
    "[Blog Link on the technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "Instead of comparing vectors one by one, you could use the approximate nearest neighbor (ANN) approach to improve search times. Many ANN algorithms use vector quantization (VQ), in which you split the vector space into multiple groups, define \"codewords\" to represent each group, and search only for those codewords. This VQ technique dramatically enhances query speeds and is the essential part of many ANN algorithms, just like indexing is the essential part of relational databases and full-text search engines.\n",
    "\n",
    "![](img/vectorQuant.gif)\n",
    "\n",
    "\n",
    "As you may be able to conclude from the diagram above, as the number of groups in the space increases the speed of the search decreases and the accuracy increases.  Managing this trade-off — getting higher accuracy at shorter latency — has been a key challenge with ANN algorithms. \n",
    "\n",
    "Last year, Google Research announced ScaNN, a new solution that provides state-of-the-art results for this challenge. With ScaNN, they introduced a new VQ algorithm called anisotropic vector quantization:\n",
    "\n",
    "![](img/Loss_Types.max-1000x1000.png)\n",
    "\n",
    "Anisotropic vector quantization uses a new loss function to train a model for VQ for an optimal grouping to capture farther data points (i.e. higher inner product) in a single group. With this idea, the new algorithm gives you higher accuracy at lower latency, as you can see in the benchmark result below (the violet line): \n",
    "\n",
    "![](img/speedvsaccuracy.max-1600x1600.png)\n",
    "\n",
    "[You can see 20% increase in performance vs. standard SOLR-type algos , 15% ish for FAISS](https://ann-benchmarks.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also quickly break down the parameters and suggeted settings\n",
    "\n",
    "```python\n",
    "  \"contentsDeltaUri\": \"gs://BUCKET_NAME/path\",\n",
    "  \"config\": {\n",
    "    \"dimensions\": 100,\n",
    "    \"approximateNeighborsCount\": 150,\n",
    "    \"distanceMeasureType\": \"DOT_PRODUCT_DISTANCE\",\n",
    "    \"shardSize\": \"SHARD_SIZE_MEDIUM\",\n",
    "    \"algorithm_config\": {\n",
    "      \"treeAhConfig\": {\n",
    "        \"leafNodeEmbeddingCount\": 5000,\n",
    "        \"leafNodesToSearchPercent\": 3\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "- `dimensions` size of the embeddings stored in the index\n",
    "- `approximateNeighborsCount` set this to increase approximate results for a search. Latency increases proprotinately, but recall does as well\n",
    "- `shardSize` defaults to medium, but general rule of thumb is to try to go as large as budget allows - going to a large shard can often help performance\n",
    "- `distanceMeasureType` can be squared l2, l1, cosine, dot product, unit l2\n",
    "\n",
    "#### config details (important still!)\n",
    "- `leafNodeEmbeddingCount` - number of embeddings in each cluster/leaf\n",
    "- `leafNodesToSearchPercent` - the percentage of leaf/clusters searched for any given query - this number is an int but treated as a percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omlgEZ-sGoM5",
    "tags": []
   },
   "source": [
    "## Update Indexes\n",
    "\n",
    "Create incremental data file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDAvm_mj_BVs"
   },
   "outputs": [],
   "source": [
    "with open(\"glove100_incremental.json\", \"w\") as f:\n",
    "    index = 0\n",
    "    f.write(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"id\": str(index),\n",
    "                \"embedding\": [str(0) for _ in train[index]],\n",
    "                \"restricts\": [\n",
    "                    {\n",
    "                        \"namespace\": \"class\",\n",
    "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU7TU7C7GoM6"
   },
   "source": [
    "Copy the incremental data file to a new subdirectory.\n",
    "\n",
    "\n",
    "#### Note from the PM on Compaction\n",
    "\n",
    "`Periodically, your index is rebuilt to account for all new updates since your last rebuild. This rebuild, or \"compaction\", improves query performance and reliability. Compactions occur for both Streaming Updates and Batch Updates.`\n",
    "\n",
    "```\n",
    "Streaming Update: Occurs when the uncompacted data size is > 1 GB or the oldest uncompacted data is at least three days old. You are billed for the cost of rebuilding the index at the same rate of a batch update, in addition to the Streaming Update costs.\n",
    "Batch Update: Occurs when the incremental dataset size is > 20% of the base dataset size.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Note on autoscaling too\n",
    "\n",
    "You can autoscale when creating in index in gcloud (not the SDK). Example is [here](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public#autoscaling), however mutation of an existing index is recommended since we will create with the SDK\n",
    "\n",
    "\n",
    "\n",
    "Notes from the PM on bursting to large scale (help with big retailer): \n",
    "\n",
    "```\n",
    "We support autoscaling. Just set max-replica-count to a large enough number, ME will respond the the peak load by increasing the number of replicas (gradually). Beneath the surface, autoscaling is handled by GKE (HPA) and scale up happens when the CPU load of existing pods exceeds 50%. That being said, the autocaling can be slow - new pods need 30 - 60 minutes to be ready and the scaling up is like a staircase. Scale down is usually much faster. When the pods are overloaded, the throttle/reject new requests and return RESOURCE_EXHAUSTED errors. If the customer knows when the peak comes, we recommend manual scaling instead - manually update the deployed index to set the min-replica-count to a high enough value\n",
    "```\n",
    "\n",
    "[Link to mutating resource config on an index](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public#autoscaling)\n",
    "\n",
    "\n",
    "Best resources for QPS\n",
    "\n",
    "n2d-standard-32 is the most powerful machine type we have and it's most cost effective for heavy/batch load.\n",
    "Each n2d-standard-32  can handle 1k - 10k QPS depends on lots of factors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLWcDvNLGoM6"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_UPDATE_URI = f\"{BUCKET_URI}/matching-engine/incremental/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgpEDX0oGoM6"
   },
   "outputs": [],
   "source": [
    "! gsutil cp glove100_incremental.json {EMBEDDINGS_UPDATE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiXtF_x0GoM6"
   },
   "source": [
    "Create update index request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvedBONtGoM6"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = tree_ah_index.update_embeddings(\n",
    "    contents_delta_uri=EMBEDDINGS_UPDATE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKPDojFpGoM6"
   },
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD"
   },
   "source": [
    "## Create an IndexEndpoint with Private Service Connect (PSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPT_NAME = \"index_endpoint_for_demo\"\n",
    "SHARED_VPC_PROJECT_ID = \"shared-vpc-admin\"\n",
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform_v1 import IndexEndpointServiceClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_request = {\"display_name\": INDEX_ENDPT_NAME}\n",
    "index_endpoint_request[\"private_service_connect_config\"] = {\"enable_private_service_connect\": True,\n",
    "                                                                \"project_allowlist\": [PROJECT_ID, SHARED_VPC_PROJECT_ID]}\n",
    "\n",
    "index_endpoint_client = IndexEndpointServiceClient(client_options=dict(api_endpoint=ENDPOINT))\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT,\n",
    "    index_endpoint=index_endpoint_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if r.done():\n",
    "        break\n",
    "    time.sleep(60)\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = r.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PJ3bcZqi-cfM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/896267025569/locations/us-central1/indexEndpoints/5550818482129469440'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = index_endpoint.name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME=\"7953488883331629056\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2cgVuuIe9k"
   },
   "source": [
    "## Deploy Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ew1UgcIIiJG"
   },
   "source": [
    "### Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nLOYTGygIlMK"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"tree_ah_glove_deployed_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_uK4WOgqN1NG",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/896267025569/locations/us-central1/indexEndpoints/7953488883331629056\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/896267025569/locations/us-central1/indexEndpoints/7953488883331629056/operations/3728800927470059520\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/896267025569/locations/us-central1/indexEndpoints/7953488883331629056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"tree_ah_glove_deployed_unique\"\n",
       "index: \"projects/896267025569/locations/us-central1/indexes/7665258507179917312\"\n",
       "create_time {\n",
       "  seconds: 1692397310\n",
       "  nanos: 508009000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/n10ed740331319020-tp/regions/us-central1/serviceAttachments/sa-gkedpm-f1608166dec39d7b39e0683f85fe14\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1692397525\n",
       "  nanos: 116475000\n",
       "}\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, \n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    machine_type=\"e2-standard-2\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNZnXmO5AhDO"
   },
   "source": [
    "### Deploy Brute Force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3p9e4828AkSv"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"glove_brute_force_deployed_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-2kgd01SA4rk",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/879733203437355008\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"glove_brute_force_deployed_unique\"\n",
       "index: \"projects/1023019892523/locations/us-central1/indexes/4679758982326255616\"\n",
       "create_time {\n",
       "  seconds: 1691031373\n",
       "  nanos: 588240000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1691031708\n",
       "  nanos: 737742000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       ", id: \"tree_ah_glove_deployed_unique\"\n",
       "index: \"projects/1023019892523/locations/us-central1/indexes/2049656799941885952\"\n",
       "create_time {\n",
       "  seconds: 1691031295\n",
       "  nanos: 81854000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1691031510\n",
       "  nanos: 319646000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=brute_force_index, \n",
    "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    # machine_type=\"\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Config Needed for PSC\n",
    "\n",
    "Ask Walmart Strati team to create these for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ATTACHMENT_URI=\"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
    "\n",
    "NETWORK_NAME=\"projects/860472322816/global/networks/host-shared-vpc\"\n",
    "ADDRESS_NAME=\"vme-psc-address-svc-for-demo\"\n",
    "REGION=\"us-central1\"\n",
    "SUBNET_NAME=\"projects/axel-host-shared-vpc/regions/us-central1/subnetworks/host-shared-vpc\"\n",
    "SVC_PROJECT=\"axel-argolis-1\"\n",
    "ENDPOINT_NAME=\"psc-endpoint-for-vme-demo\"\n",
    "\n",
    "gcloud compute addresses create ${ADDRESS_NAME:?} \\\n",
    "    --region=${REGION:?} \\\n",
    "    --subnet=${SUBNET_NAME:?} \\\n",
    "    --project=${SVC_PROJECT:?}\n",
    "\n",
    "gcloud compute forwarding-rules create ${ENDPOINT_NAME:?} \\\n",
    "    --network=${NETWORK_NAME:?} \\\n",
    "    --address=${ADDRESS_NAME:?} \\\n",
    "    --target-service-attachment=${SERVICE_ATTACHMENT_URI:?} \\\n",
    "    --project=${SVC_PROJECT:?} \\\n",
    "    --region=${REGION:?}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Online Queries\n",
    "\n",
    "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial).\n",
    "\n",
    "The `filter` parameter is an optional way to filter for a subset of embeddings. In this case, only embeddings that have the `class` set as `even` are returned.\n",
    "\n",
    "Filters are applied before and more info on the methods can be found here:\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_find_neighbors\n",
    "\n",
    "```\n",
    "List[Namespace]\n",
    "Optional. A list of Namespaces for filtering the matching results. For example, [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])] will match datapoints that satisfy \"red color\" but not include datapoints with \"squared shape\". Please refer to https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json for more detail.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPT_IP = \"250.0.26.250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchNeighbor, Namespace\n",
    "import grpc\n",
    "from google.cloud.aiplatform.matching_engine._protos import match_service_pb2\n",
    "from google.cloud.aiplatform.matching_engine._protos import (\n",
    "    match_service_pb2_grpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vme_grpc_match(endpt_ip, deployed_index_id, n_matches, embeddings, filter=[]):\n",
    "    # Set up channel and stub\n",
    "    channel = grpc.insecure_channel(\"{}:10000\".format(endpt_ip))\n",
    "    stub = match_service_pb2_grpc.MatchServiceStub(channel)\n",
    "\n",
    "    # Create the batch match request\n",
    "    batch_request = match_service_pb2.BatchMatchRequest()\n",
    "    batch_request_for_index = (\n",
    "        match_service_pb2.BatchMatchRequest.BatchMatchRequestPerIndex()\n",
    "    )\n",
    "    batch_request_for_index.deployed_index_id = deployed_index_id\n",
    "    b_requests = []\n",
    "    for query in embeddings:\n",
    "        request = match_service_pb2.MatchRequest(\n",
    "            num_neighbors=n_matches,\n",
    "            deployed_index_id=deployed_index_id,\n",
    "            float_val=query,\n",
    "        )\n",
    "        for namespace in filter:\n",
    "            restrict = match_service_pb2.Namespace()\n",
    "            restrict.name = namespace.name\n",
    "            restrict.allow_tokens.extend(namespace.allow_tokens)\n",
    "            restrict.deny_tokens.extend(namespace.deny_tokens)\n",
    "            request.restricts.append(restrict)\n",
    "        b_requests.append(request)\n",
    "\n",
    "    batch_request_for_index.requests.extend(b_requests)\n",
    "    batch_request.requests.append(batch_request_for_index)\n",
    "\n",
    "    # Perform the request\n",
    "    response = stub.BatchMatch(batch_request)\n",
    "\n",
    "    # Wrap the results in MatchNeighbor objects and return\n",
    "    neighbors = [\n",
    "                    [\n",
    "                        MatchNeighbor(id=neighbor.id, distance=neighbor.distance)\n",
    "                        for neighbor in embedding_neighbors.neighbor\n",
    "                    ]\n",
    "                    for embedding_neighbors in response.responses[0].responses\n",
    "                ]\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='310080', distance=18.029903411865234),\n",
       "  MatchNeighbor(id='702494', distance=16.84667205810547),\n",
       "  MatchNeighbor(id='505832', distance=16.334247589111328),\n",
       "  MatchNeighbor(id='825418', distance=16.22643280029297),\n",
       "  MatchNeighbor(id='707954', distance=16.183256149291992),\n",
       "  MatchNeighbor(id='436242', distance=16.11363410949707),\n",
       "  MatchNeighbor(id='955052', distance=16.022321701049805),\n",
       "  MatchNeighbor(id='20414', distance=15.94982624053955),\n",
       "  MatchNeighbor(id='208920', distance=15.804502487182617),\n",
       "  MatchNeighbor(id='380434', distance=15.756570816040039)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"even\"])])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='899605', distance=20.079139709472656),\n",
       "  MatchNeighbor(id='729301', distance=18.31948471069336),\n",
       "  MatchNeighbor(id='1093903', distance=17.839481353759766),\n",
       "  MatchNeighbor(id='296543', distance=16.99886703491211),\n",
       "  MatchNeighbor(id='21495', distance=16.8770694732666),\n",
       "  MatchNeighbor(id='689839', distance=16.852933883666992),\n",
       "  MatchNeighbor(id='518781', distance=16.65009307861328),\n",
       "  MatchNeighbor(id='405251', distance=16.278234481811523),\n",
       "  MatchNeighbor(id='1142011', distance=16.186227798461914),\n",
       "  MatchNeighbor(id='724903', distance=16.18083953857422)]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "A3KYVw5HB-4v",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.22 ms ± 277 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeUZO3bAGoM-"
   },
   "source": [
    "### Compute Recall\n",
    "\n",
    "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. Note that you can run multiple queries in a single match call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "U9dNIbkEGoM-"
   },
   "outputs": [],
   "source": [
    "# Retrieve nearest neighbors for both the tree-AH index and the brute-force index\n",
    "tree_ah_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, list(test))\n",
    "\n",
    "brute_force_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_BRUTE_FORCE_INDEX_ID, NUM_NEIGHBOURS, list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "V-eMF05UGoM-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5787\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
    "recalled_neighbors = 0\n",
    "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "    tree_ah_response_test, brute_force_response_test\n",
    "):\n",
    "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "    recalled_neighbors += len(\n",
    "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "    )\n",
    "\n",
    "recall = recalled_neighbors / len(\n",
    "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
    ")\n",
    "\n",
    "print(\"Recall: {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndexEndpoint : projects/896267025569/locations/us-central1/indexEndpoints/5550818482129469440\n",
      "Delete MatchingEngineIndexEndpoint  backing LRO: projects/896267025569/locations/us-central1/operations/3287377795243573248\n",
      "MatchingEngineIndexEndpoint deleted. . Resource name: projects/896267025569/locations/us-central1/indexEndpoints/5550818482129469440\n"
     ]
    }
   ],
   "source": [
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "omj7N9iWv-Tq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndex : projects/896267025569/locations/us-central1/indexes/3242512566869557248\n",
      "Delete MatchingEngineIndex  backing LRO: projects/896267025569/locations/us-central1/indexes/3242512566869557248/operations/27193877492400128\n",
      "MatchingEngineIndex deleted. . Resource name: projects/896267025569/locations/us-central1/indexes/3242512566869557248\n"
     ]
    }
   ],
   "source": [
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "brute_force_index.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also!\n",
    "See this notebook that does ** Not ** use the SDK but shows a streaming index:\n",
    "\n",
    "[link here](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/matching_engine/stream_update_for_matching_engine.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk_matching_engine_for_indexing.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-genai-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3 (genai)",
   "language": "python",
   "name": "conda-env-genai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
