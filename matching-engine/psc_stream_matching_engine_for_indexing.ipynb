{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Create Vertex AI Matching Engine index - Streaming w/ PSC\n",
    "![ ](https://www.google-analytics.com/collect?v=2&tid=G-L6X3ECH596&cid=1&en=page_view&sid=1&dt=sdk_matching_engine_for_indexing.ipynb&dl=notebooks%2Fofficial%2Fmatching_engine%2Fsdk_matching_engine_for_indexing.ipynb)\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "      <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/matching_engine/sdk_matching_engine_for_indexing.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0a74aaf1481"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This example demonstrates how to use the Vertex AI ANN Service. It is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it is a fully managed offering, further reducing operational overhead. It is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
    "\n",
    "Learn more about [Vertex AI Matching Engine](https://cloud.google.com/vertex-ai/docs/matching-engine/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34a4b245e795"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you learn how to create Approximate Nearest Neighbor (ANN) Index, query against indexes, and validate the performance of the index. \n",
    "\n",
    "This tutorial uses the following Google Cloud ML services:\n",
    "\n",
    "- `Vertex AI Matching Engine`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "* Create ANN Index and Brute Force Index\n",
    "* Create an IndexEndpoint with Private Service Connect (PSC)\n",
    "* Deploy ANN Index and Brute Force Index\n",
    "* Perform online query\n",
    "* Compute recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [GloVe dataset](https://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "\"GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workbench Instance with Conda Env as Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Vertex Workbench Instance [here](https://console.cloud.google.com/vertex-ai/workbench/instances/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new conda environment to use as a jupyter kernel\n",
    "\n",
    "Run the following commands in the terminal of your Vertex Workbench Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new conda environment with Python 3.10 and ipykernel\n",
    "```bash\n",
    "CONDA_ENV_NAME=\"vme\"\n",
    "conda create -n $CONDA_ENV_NAME python=3.10 ipykernel\n",
    "```\n",
    "2. Change the display name of the jupyter kernel to Python 3 (env_name)\n",
    "```bash\n",
    "mv /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json /tmp/temp.json && jq -r '.display_name |= \"Python 3 ('$CONDA_ENV_NAME')\"' /tmp/temp.json > /opt/conda/envs/$CONDA_ENV_NAME/share/jupyter/kernels/python3/kernel.json && rm /tmp/temp.json\n",
    "```\n",
    "3. Deactivate conda environment\n",
    "```bash\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your new jupyter kernel for this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0f1bea346db"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Cloud Storage, BigQuery and Vertex AI SDKs for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irSMQn6gZ19l"
   },
   "source": [
    "Install the `h5py` to prepare sample dataset, and the `grpcio-tools` for querying against the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dfbccc635a17",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Obtaining dependency information for google-cloud-aiplatform from https://files.pythonhosted.org/packages/8f/3f/979e65dc13c11b4c53241d105d41d4b937b131e56b68397cc279f372be96/google_cloud_aiplatform-1.28.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_aiplatform-1.28.1-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Obtaining dependency information for google-cloud-storage from https://files.pythonhosted.org/packages/88/14/c9d4faae7ea4bff4405152cbc762b61100aa6949273b4eb3203d23308670/google_cloud_storage-2.10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_storage-2.10.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting grpcio-tools\n",
      "  Obtaining dependency information for grpcio-tools from https://files.pythonhosted.org/packages/ef/86/499bfeb0a1e27c5f5b0204964112f345a1b8bb262b05992b52319e381bb6/grpcio_tools-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio_tools-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting h5py\n",
      "  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/0d/7a/e55589e4093cca1934db5e99644c1c2424a9b3aac104b7f6176605a5eeb7/h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 from https://files.pythonhosted.org/packages/6e/c4/c3cd048b6cbeba8d9ae50dd7643ac065b85237338aa7501b0efae91eb4d9/google_api_core-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.0 from https://files.pythonhosted.org/packages/36/5b/e02636d221917d6fa2a61289b3f16002eb4c93d51c0191ac8e896d527182/proto_plus-1.22.3-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 from https://files.pythonhosted.org/packages/01/cb/445b3e465abdb8042a41957dc8f60c54620dc7540dbcf9b458a921531ca2/protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/envs/vme/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-bigquery<4.0.0dev,>=1.15.0 from https://files.pythonhosted.org/packages/cc/6a/d0ef792288f2fa2cfea80899a82de302b3332dfda41984fe114e2cfbf700/google_cloud_bigquery-3.11.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_bigquery-3.11.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Obtaining dependency information for google-cloud-resource-manager<3.0.0dev,>=1.3.3 from https://files.pythonhosted.org/packages/cb/88/4fc0d6be354fbf74e8192937ef58661fce38bbf188450f952da97f3ebb47/google_cloud_resource_manager-1.10.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_resource_manager-1.10.2-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting shapely<2.0.0 (from google-cloud-aiplatform)\n",
      "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0dev,>=1.25.0 (from google-cloud-storage)\n",
      "  Obtaining dependency information for google-auth<3.0dev,>=1.25.0 from https://files.pythonhosted.org/packages/9c/8d/bff87fc722553a5691d8514da5523c23547f3894189ba03b57592e37bdc2/google_auth-2.22.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Obtaining dependency information for google-cloud-core<3.0dev,>=2.3.0 from https://files.pythonhosted.org/packages/a2/40/02045f776fdb6e44194f34b6375a26ce8a61bd9bd03cd8930ed91cf51a62/google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-resumable-media>=2.3.2 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0 (from google-cloud-storage)\n",
      "  Obtaining dependency information for requests<3.0.0dev,>=2.18.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting grpcio>=1.56.2 (from grpcio-tools)\n",
      "  Obtaining dependency information for grpcio>=1.56.2 from https://files.pythonhosted.org/packages/a7/a1/28173a3ea544075159f968f6a80b455c6c06381084878b9cdce31acf3cf6/grpcio-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/vme/lib/python3.10/site-packages (from grpcio-tools) (68.0.0)\n",
      "Collecting numpy>=1.17.3 (from h5py)\n",
      "  Obtaining dependency information for numpy>=1.17.3 from https://files.pythonhosted.org/packages/71/3c/3b1981c6a1986adc9ee7db760c0c34ea5b14ac3da9ecfcf1ea2a4ec6c398/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/a7/bc/416a1ffeba4dcd072bc10523dac9ed97f2e7fc4b760580e2bdbdc1e2afdd/googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/ef/16/3018689d96918e9c4c7407adf96b721df4d6748ba65db82c5eaa63564335/grpcio_status-1.56.2-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0dev,>=1.25.0->google-cloud-storage)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=1.25.0->google-cloud-storage)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3.0dev,>=1.25.0->google-cloud-storage)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/vme/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Collecting urllib3<2.0 (from google-auth<3.0dev,>=1.25.0->google-cloud-storage)\n",
      "  Obtaining dependency information for urllib3<2.0 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/envs/vme/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media>=2.3.2->google-cloud-storage)\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0dev,>=2.18.0->google-cloud-storage)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/a4/65/057bf29660aae6ade0816457f8db4e749e5c0bfa2366eb5f67db9912fa4c/charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0dev,>=2.18.0->google-cloud-storage)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3.0.0dev,>=2.18.0->google-cloud-storage)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.28.1-py2.py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.11.4-py2.py3-none-any.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.10.2-py2.py3-none-any.whl (321 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.56.2-py3-none-any.whl (5.1 kB)\n",
      "Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, shapely, pyasn1, protobuf, numpy, idna, grpcio, google-crc32c, charset-normalizer, certifi, cachetools, rsa, requests, pyasn1-modules, proto-plus, h5py, grpcio-tools, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "Successfully installed cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.2.0 google-api-core-2.11.1 google-auth-2.22.0 google-cloud-aiplatform-1.28.1 google-cloud-bigquery-3.11.4 google-cloud-core-2.3.3 google-cloud-resource-manager-1.10.2 google-cloud-storage-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 grpc-google-iam-v1-0.12.6 grpcio-1.56.2 grpcio-status-1.56.2 grpcio-tools-1.56.2 h5py-3.9.0 idna-3.4 numpy-1.25.2 proto-plus-1.22.3 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 rsa-4.9 shapely-1.8.5.post1 urllib3-1.26.16\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        grpcio-tools \\\n",
    "                        h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd28c9e4f067"
   },
   "source": [
    "## Before you begin\n",
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "80c0215f05a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"wmt-7fbls2a91f025anb93e025b02g\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! echo Y | gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f4512bf63b3"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "474be5183c27"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "949271bfebe3"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b65b4ce80d9a"
   },
   "source": [
    "**1. Vertex AI Workbench**\n",
    "* Do nothing as you are already authenticated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "985cdbfe7372"
   },
   "source": [
    "**2. Local JupyterLab instance, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fbc9cd30cc4b"
   },
   "outputs": [],
   "source": [
    "# ! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79efab26ad02"
   },
   "source": [
    "**3. Colab, uncomment and run:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a336a05c6149"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c0a44fa330f"
   },
   "source": [
    "**4. Service account or other**\n",
    "* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5de53b31bf1"
   },
   "source": [
    "## Make sure the following cells are run from inside the VPC network that you created in the previous step.\n",
    "\n",
    "* **WARNING:** The MatchingIndexEndpoint.match method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
    "  * **In the same region as where your ANN service is deployed** (for example, if you set `REGION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
    "  * If you run it in the colab or a Vertex AI Workbench notebook instance in a different VPC network or region, \"Create Online Queries\" section will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://wmt-aug23-vertexgenai-workshop-data/matching-engine\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://embeddings-for-kroger/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR6Wwv-hCCN-"
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "The GloVe dataset consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" split, and a \"test\" split.\n",
    "We will create a vector search index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the vector search index.\n",
    "\n",
    "**Note:** While the data split uses the term \"train\", these are pre-trained embeddings and therefore are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with machine learning terminology.\n",
    "\n",
    "Download the GloVe dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9wzS85TeB9dG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://wmt-aug23-vertexgenai-workshop-data/matching-engine/data/glove-100-angular.hdf5...\n",
      "- [1/1 files][462.9 MiB/462.9 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/462.9 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp gs://wmt-aug23-vertexgenai-workshop-data/matching-engine/data/glove-100-angular.hdf5 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fAO9CMoCNtq"
   },
   "source": [
    "Read the data into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lZ3JQTS6CN-3"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# The number of nearest neighbors to be retrieved from database for each query.\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
    "train = h5[\"train\"]\n",
    "test = h5[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pE6bBBo7GjJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11333  ,  0.48402  ,  0.090771 , -0.22439  ,  0.034206 ,\n",
       "       -0.55831  ,  0.041849 , -0.53573  ,  0.18809  , -0.58722  ,\n",
       "        0.015313 , -0.014555 ,  0.80842  , -0.038519 ,  0.75348  ,\n",
       "        0.70502  , -0.17863  ,  0.3222   ,  0.67575  ,  0.67198  ,\n",
       "        0.26044  ,  0.4187   , -0.34122  ,  0.2286   , -0.53529  ,\n",
       "        1.2582   , -0.091543 ,  0.19716  , -0.037454 , -0.3336   ,\n",
       "        0.31399  ,  0.36488  ,  0.71263  ,  0.1307   , -0.24654  ,\n",
       "       -0.52445  , -0.036091 ,  0.55068  ,  0.10017  ,  0.48095  ,\n",
       "        0.71104  , -0.053462 ,  0.22325  ,  0.30917  , -0.39926  ,\n",
       "        0.036634 , -0.35431  , -0.42795  ,  0.46444  ,  0.25586  ,\n",
       "        0.68257  , -0.20821  ,  0.38433  ,  0.055773 , -0.2539   ,\n",
       "       -0.20804  ,  0.52522  , -0.11399  , -0.3253   , -0.44104  ,\n",
       "        0.17528  ,  0.62255  ,  0.50237  , -0.7607   , -0.071786 ,\n",
       "        0.0080131, -0.13286  ,  0.50097  ,  0.18824  , -0.54722  ,\n",
       "       -0.42664  ,  0.4292   ,  0.14877  , -0.0072514, -0.16484  ,\n",
       "       -0.059798 ,  0.9895   , -0.61738  ,  0.054169 ,  0.48424  ,\n",
       "       -0.35084  , -0.27053  ,  0.37829  ,  0.11503  , -0.39613  ,\n",
       "        0.24266  ,  0.39147  , -0.075256 ,  0.65093  , -0.20822  ,\n",
       "       -0.17456  ,  0.53571  , -0.16537  ,  0.13582  , -0.56016  ,\n",
       "        0.016964 ,  0.1277   ,  0.94071  , -0.22608  , -0.021106 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQIQSyF9GtSv"
   },
   "source": [
    "#### Save the train split in JSONL format.\n",
    "\n",
    "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
    "\n",
    "Additionally, to demonstrate the filtering functionality, the `restricts` key is set such that each embedding has a different `class`, `even` or `odd`. These are used during the later matching step to filter for results.\n",
    "See additional information of filtering here: https://cloud.google.com/vertex-ai/docs/matching-engine/filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "57fe2ce4b50f"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"glove100.json\", \"w\") as f:\n",
    "    embeddings_formatted = [\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"id\": str(index),\n",
    "                \"embedding\": [str(value) for value in embedding],\n",
    "                \"restricts\": [\n",
    "                    {\n",
    "                        \"namespace\": \"class\",\n",
    "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "        for index, embedding in enumerate(train)\n",
    "    ]\n",
    "    f.writelines(embeddings_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "Upload the training data to GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [],
   "source": [
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine_demo/initial/\"\n",
    "! gsutil -m cp glove100.json {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "## Create Indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhIBCQ7dDSbW"
   },
   "source": [
    "### Create ANN Index (for Production Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qiIg9b5zJLi1"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 100\n",
    "DISPLAY_NAME = \"stream_glove_100_1\"\n",
    "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svLYiDf0OD2G"
   },
   "source": [
    "Create the ANN index configuration:\n",
    "\n",
    "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup/format-structure).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = aiplatform_v1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeAhConfig = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=7),\n",
    "    }\n",
    ")\n",
    "\n",
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "        \"shardSize\": struct_pb2.Value(string_value=\"SHARD_SIZE_SMALL\")\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME,\n",
    "    \"description\": \"Glove 100 ANN index - stream\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/896267025569/locations/us-central1/indexes/7485114522085097472\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/896267025569/locations/us-central1/indexes/7485114522085097472'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME=\"3053572488752529408\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f1a9fbecabb"
   },
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1ddb70647d98"
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsqZuyoA1SG"
   },
   "source": [
    "### Create Brute Force Index (for Ground Truth)\n",
    "\n",
    "The brute force index uses a naive brute force method to find the nearest neighbors. This method is not fast or efficient. Hence brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors, so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an apples to apples comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
    "\n",
    "Create the brute force index configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"bruteForceConfig\": struct_pb2.Value(struct_value={})}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS_INITIAL_URI),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME_BRUTE_FORCE,\n",
    "    \"description\": \"Glove 100 index (brute force) - stream\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "    \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m INDEX_BRUTE_FORCE_RESOURCE_NAME \u001b[38;5;241m=\u001b[39m \u001b[43mann_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m()\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m      2\u001b[0m INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_BRUTE_FORCE_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_BRUTE_FORCE_RESOURCE_NAME = \"3778652028759179264\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "865fcad494d7"
   },
   "outputs": [],
   "source": [
    "brute_force_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This takes 20-30 minutes - here's some reading on what it is doing\n",
    "#### Note on the advantages of the algorithm\n",
    "\n",
    "[link](https://arxiv.org/pdf/1908.10396.pdf)\n",
    "\n",
    "```However, it is easy to see that not all pairs of (x, q) are equally important. The approximation error on the pairs which have a high inner product is far more important since they are likely to be among the top ranked pairs and can greatly affect the search result, while for the pairs whose inner product is low the approximation error matters much less. In other words, for a given datapoint x, we should quantize it with a bigger focus on its error with those queries which have high inner product with x. See Figure 1 for the illustration.```\n",
    "\n",
    "\n",
    "![](img/algo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other quick notes on ME while we wait for deployment\n",
    "\n",
    "[Blog Link on the technology](https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology)\n",
    "\n",
    "Instead of comparing vectors one by one, you could use the approximate nearest neighbor (ANN) approach to improve search times. Many ANN algorithms use vector quantization (VQ), in which you split the vector space into multiple groups, define \"codewords\" to represent each group, and search only for those codewords. This VQ technique dramatically enhances query speeds and is the essential part of many ANN algorithms, just like indexing is the essential part of relational databases and full-text search engines.\n",
    "\n",
    "![](img/vectorQuant.gif)\n",
    "\n",
    "\n",
    "As you may be able to conclude from the diagram above, as the number of groups in the space increases the speed of the search decreases and the accuracy increases.  Managing this trade-off — getting higher accuracy at shorter latency — has been a key challenge with ANN algorithms. \n",
    "\n",
    "Last year, Google Research announced ScaNN, a new solution that provides state-of-the-art results for this challenge. With ScaNN, they introduced a new VQ algorithm called anisotropic vector quantization:\n",
    "\n",
    "![](img/Loss_Types.max-1000x1000.png)\n",
    "\n",
    "Anisotropic vector quantization uses a new loss function to train a model for VQ for an optimal grouping to capture farther data points (i.e. higher inner product) in a single group. With this idea, the new algorithm gives you higher accuracy at lower latency, as you can see in the benchmark result below (the violet line): \n",
    "\n",
    "![](img/speedvsaccuracy.max-1600x1600.png)\n",
    "\n",
    "[You can see 20% increase in performance vs. standard SOLR-type algos , 15% ish for FAISS](https://ann-benchmarks.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also quickly break down the parameters and suggeted settings\n",
    "\n",
    "```python\n",
    "  \"contentsDeltaUri\": \"gs://BUCKET_NAME/path\",\n",
    "  \"config\": {\n",
    "    \"dimensions\": 100,\n",
    "    \"approximateNeighborsCount\": 150,\n",
    "    \"distanceMeasureType\": \"DOT_PRODUCT_DISTANCE\",\n",
    "    \"shardSize\": \"SHARD_SIZE_MEDIUM\",\n",
    "    \"algorithm_config\": {\n",
    "      \"treeAhConfig\": {\n",
    "        \"leafNodeEmbeddingCount\": 5000,\n",
    "        \"leafNodesToSearchPercent\": 3\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "- `dimensions` size of the embeddings stored in the index\n",
    "- `approximateNeighborsCount` set this to increase approximate results for a search. Latency increases proprotinately, but recall does as well\n",
    "- `shardSize` defaults to medium, but general rule of thumb is to try to go as large as budget allows - going to a large shard can often help performance\n",
    "- `distanceMeasureType` can be squared l2, l1, cosine, dot product, unit l2\n",
    "\n",
    "#### config details (important still!)\n",
    "- `leafNodeEmbeddingCount` - number of embeddings in each cluster/leaf\n",
    "- `leafNodesToSearchPercent` - the percentage of leaf/clusters searched for any given query - this number is an int but treated as a percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omlgEZ-sGoM5",
    "tags": []
   },
   "source": [
    "## Stream Update Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU7TU7C7GoM6"
   },
   "source": [
    "#### Note from the PM on Compaction\n",
    "\n",
    "`Periodically, your index is rebuilt to account for all new updates since your last rebuild. This rebuild, or \"compaction\", improves query performance and reliability. Compactions occur for both Streaming Updates and Batch Updates.`\n",
    "\n",
    "```\n",
    "Streaming Update: Occurs when the uncompacted data size is > 1 GB or the oldest uncompacted data is at least three days old. You are billed for the cost of rebuilding the index at the same rate of a batch update, in addition to the Streaming Update costs.\n",
    "Batch Update: Occurs when the incremental dataset size is > 20% of the base dataset size.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Note on autoscaling too\n",
    "\n",
    "You can autoscale when creating in index in gcloud (not the SDK). Example is [here](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public#autoscaling), however mutation of an existing index is recommended since we will create with the SDK\n",
    "\n",
    "\n",
    "\n",
    "Notes from the PM on bursting to large scale (help with big retailer): \n",
    "\n",
    "```\n",
    "We support autoscaling. Just set max-replica-count to a large enough number, ME will respond the the peak load by increasing the number of replicas (gradually). Beneath the surface, autoscaling is handled by GKE (HPA) and scale up happens when the CPU load of existing pods exceeds 50%. That being said, the autocaling can be slow - new pods need 30 - 60 minutes to be ready and the scaling up is like a staircase. Scale down is usually much faster. When the pods are overloaded, the throttle/reject new requests and return RESOURCE_EXHAUSTED errors. If the customer knows when the peak comes, we recommend manual scaling instead - manually update the deployed index to set the min-replica-count to a high enough value\n",
    "```\n",
    "\n",
    "[Link to mutating resource config on an index](https://cloud.google.com/vertex-ai/docs/matching-engine/deploy-index-public#autoscaling)\n",
    "\n",
    "\n",
    "Best resources for QPS\n",
    "\n",
    "n2d-standard-32 is the most powerful machine type we have and it's most cost effective for heavy/batch load.\n",
    "Each n2d-standard-32  can handle 1k - 10k QPS depends on lots of factors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = [\n",
    "    -0.11333,\n",
    "    0.48402,\n",
    "    0.090771,\n",
    "    -0.22439,\n",
    "    0.034206,\n",
    "    -0.55831,\n",
    "    0.041849,\n",
    "    -0.53573,\n",
    "    0.18809,\n",
    "    -0.58722,\n",
    "    0.015313,\n",
    "    -0.014555,\n",
    "    0.80842,\n",
    "    -0.038519,\n",
    "    0.75348,\n",
    "    0.70502,\n",
    "    -0.17863,\n",
    "    0.3222,\n",
    "    0.67575,\n",
    "    0.67198,\n",
    "    0.26044,\n",
    "    0.4187,\n",
    "    -0.34122,\n",
    "    0.2286,\n",
    "    -0.53529,\n",
    "    1.2582,\n",
    "    -0.091543,\n",
    "    0.19716,\n",
    "    -0.037454,\n",
    "    -0.3336,\n",
    "    0.31399,\n",
    "    0.36488,\n",
    "    0.71263,\n",
    "    0.1307,\n",
    "    -0.24654,\n",
    "    -0.52445,\n",
    "    -0.036091,\n",
    "    0.55068,\n",
    "    0.10017,\n",
    "    0.48095,\n",
    "    0.71104,\n",
    "    -0.053462,\n",
    "    0.22325,\n",
    "    0.30917,\n",
    "    -0.39926,\n",
    "    0.036634,\n",
    "    -0.35431,\n",
    "    -0.42795,\n",
    "    0.46444,\n",
    "    0.25586,\n",
    "    0.68257,\n",
    "    -0.20821,\n",
    "    0.38433,\n",
    "    0.055773,\n",
    "    -0.2539,\n",
    "    -0.20804,\n",
    "    0.52522,\n",
    "    -0.11399,\n",
    "    -0.3253,\n",
    "    -0.44104,\n",
    "    0.17528,\n",
    "    0.62255,\n",
    "    0.50237,\n",
    "    -0.7607,\n",
    "    -0.071786,\n",
    "    0.0080131,\n",
    "    -0.13286,\n",
    "    0.50097,\n",
    "    0.18824,\n",
    "    -0.54722,\n",
    "    -0.42664,\n",
    "    0.4292,\n",
    "    0.14877,\n",
    "    -0.0072514,\n",
    "    -0.16484,\n",
    "    -0.059798,\n",
    "    0.9895,\n",
    "    -0.61738,\n",
    "    0.054169,\n",
    "    0.48424,\n",
    "    -0.35084,\n",
    "    -0.27053,\n",
    "    0.37829,\n",
    "    0.11503,\n",
    "    -0.39613,\n",
    "    0.24266,\n",
    "    0.39147,\n",
    "    -0.075256,\n",
    "    0.65093,\n",
    "    -0.20822,\n",
    "    -0.17456,\n",
    "    0.53571,\n",
    "    -0.16537,\n",
    "    0.13582,\n",
    "    -0.56016,\n",
    "    0.016964,\n",
    "    0.1277,\n",
    "    0.94071,\n",
    "    -0.22608,\n",
    "    -0.021106,\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"odd\"]}],\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoints=[insert_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit Datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing restricts namespace value from odd to even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_datapoints_payload = aiplatform_v1.IndexDatapoint(\n",
    "    datapoint_id=\"101\",\n",
    "    feature_vector=query,\n",
    "    restricts=[{\"namespace\": \"class\", \"allow_list\": [\"even\"]}],\n",
    ")\n",
    "\n",
    "upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoints=[insert_datapoints_payload]\n",
    ")\n",
    "\n",
    "index_client.upsert_datapoints(request=upsert_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the datapoint with id '101' from the index\n",
    "remove_request = aiplatform_v1.RemoveDatapointsRequest(\n",
    "    index=tree_ah_index.resource_name, datapoint_ids=[\"101\"]\n",
    ")\n",
    "\n",
    "index_client.remove_datapoints(request=remove_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD",
    "tags": []
   },
   "source": [
    "## Create an IndexEndpoint with Private Service Connect (PSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPT_NAME = \"index_endpoint_for_demo_1\"\n",
    "SHARED_VPC_PROJECT_ID = \"shared-vpc-admin\"\n",
    "PARENT = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform_v1 import IndexEndpointServiceClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_request = {\"display_name\": INDEX_ENDPT_NAME}\n",
    "index_endpoint_request[\"private_service_connect_config\"] = {\"enable_private_service_connect\": True,\n",
    "                                                                \"project_allowlist\": [PROJECT_ID, SHARED_VPC_PROJECT_ID]}\n",
    "\n",
    "index_endpoint_client = IndexEndpointServiceClient(client_options=dict(api_endpoint=ENDPOINT))\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT,\n",
    "    index_endpoint=index_endpoint_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if r.done():\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = r.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "PJ3bcZqi-cfM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/896267025569/locations/us-central1/indexEndpoints/4699638152556445696'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = index_endpoint.name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME = \"4699638152556445696\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2cgVuuIe9k"
   },
   "source": [
    "## Deploy Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ew1UgcIIiJG"
   },
   "source": [
    "### Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nLOYTGygIlMK"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"stream_tree_ah_glove_deployed_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_uK4WOgqN1NG",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/896267025569/locations/us-central1/indexEndpoints/4699638152556445696\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/896267025569/locations/us-central1/indexEndpoints/4699638152556445696/operations/4228630117364006912\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/896267025569/locations/us-central1/indexEndpoints/4699638152556445696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"stream_tree_ah_glove_deployed_unique\"\n",
       "index: \"projects/896267025569/locations/us-central1/indexes/3053572488752529408\"\n",
       "create_time {\n",
       "  seconds: 1692327765\n",
       "  nanos: 863918000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/n10ed740331319020-tp/regions/us-central1/serviceAttachments/sa-gkedpm-f1608166dec39d7b39e0683f85fe14\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1692328736\n",
       "  nanos: 998601000\n",
       "}\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"e2-standard-2\"\n",
       "  }\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, \n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    machine_type=\"e2-standard-2\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNZnXmO5AhDO"
   },
   "source": [
    "### Deploy Brute Force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3p9e4828AkSv"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"glove_brute_force_deployed_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-2kgd01SA4rk",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/879733203437355008\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"glove_brute_force_deployed_unique\"\n",
       "index: \"projects/1023019892523/locations/us-central1/indexes/4679758982326255616\"\n",
       "create_time {\n",
       "  seconds: 1691031373\n",
       "  nanos: 588240000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1691031708\n",
       "  nanos: 737742000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       ", id: \"tree_ah_glove_deployed_unique\"\n",
       "index: \"projects/1023019892523/locations/us-central1/indexes/2049656799941885952\"\n",
       "create_time {\n",
       "  seconds: 1691031295\n",
       "  nanos: 81854000\n",
       "}\n",
       "private_endpoints {\n",
       "  service_attachment: \"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1691031510\n",
       "  nanos: 319646000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=brute_force_index, \n",
    "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
    "    min_replica_count=2,\n",
    "    max_replica_count=2,\n",
    "    # machine_type=\"\"\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Config Needed for PSC\n",
    "\n",
    "Ask Walmart Strati team to create these for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ATTACHMENT_URI=\"projects/q11906587d2a7dda8-tp/regions/us-central1/serviceAttachments/sa-gkedpm-5f0baff4586951a9ca3e7156d753f5\"\n",
    "\n",
    "NETWORK_NAME=\"projects/860472322816/global/networks/host-shared-vpc\"\n",
    "ADDRESS_NAME=\"vme-psc-address-svc-for-demo\"\n",
    "REGION=\"us-central1\"\n",
    "SUBNET_NAME=\"projects/axel-host-shared-vpc/regions/us-central1/subnetworks/host-shared-vpc\"\n",
    "SVC_PROJECT=\"axel-argolis-1\"\n",
    "ENDPOINT_NAME=\"psc-endpoint-for-vme-demo\"\n",
    "\n",
    "gcloud compute addresses create ${ADDRESS_NAME:?} \\\n",
    "    --region=${REGION:?} \\\n",
    "    --subnet=${SUBNET_NAME:?} \\\n",
    "    --project=${SVC_PROJECT:?}\n",
    "\n",
    "gcloud compute forwarding-rules create ${ENDPOINT_NAME:?} \\\n",
    "    --network=${NETWORK_NAME:?} \\\n",
    "    --address=${ADDRESS_NAME:?} \\\n",
    "    --target-service-attachment=${SERVICE_ATTACHMENT_URI:?} \\\n",
    "    --project=${SVC_PROJECT:?} \\\n",
    "    --region=${REGION:?}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D",
    "tags": []
   },
   "source": [
    "## Create Online Queries\n",
    "\n",
    "After you built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example 'us-central1' in this tutorial).\n",
    "\n",
    "The `filter` parameter is an optional way to filter for a subset of embeddings. In this case, only embeddings that have the `class` set as `even` are returned.\n",
    "\n",
    "Filters are applied before and more info on the methods can be found here:\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint#google_cloud_aiplatform_MatchingEngineIndexEndpoint_find_neighbors\n",
    "\n",
    "```\n",
    "List[Namespace]\n",
    "Optional. A list of Namespaces for filtering the matching results. For example, [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])] will match datapoints that satisfy \"red color\" but not include datapoints with \"squared shape\". Please refer to https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json for more detail.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NEIGHBOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPT_IP = \"250.0.26.250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchNeighbor, Namespace\n",
    "import grpc\n",
    "from google.cloud.aiplatform.matching_engine._protos import match_service_pb2\n",
    "from google.cloud.aiplatform.matching_engine._protos import (\n",
    "    match_service_pb2_grpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vme_grpc_match(endpt_ip, deployed_index_id, n_matches, embeddings, filter=[]):\n",
    "    # Set up channel and stub\n",
    "    channel = grpc.insecure_channel(\"{}:10000\".format(endpt_ip))\n",
    "    stub = match_service_pb2_grpc.MatchServiceStub(channel)\n",
    "\n",
    "    # Create the batch match request\n",
    "    batch_request = match_service_pb2.BatchMatchRequest()\n",
    "    batch_request_for_index = (\n",
    "        match_service_pb2.BatchMatchRequest.BatchMatchRequestPerIndex()\n",
    "    )\n",
    "    batch_request_for_index.deployed_index_id = deployed_index_id\n",
    "    b_requests = []\n",
    "    for query in embeddings:\n",
    "        request = match_service_pb2.MatchRequest(\n",
    "            num_neighbors=n_matches,\n",
    "            deployed_index_id=deployed_index_id,\n",
    "            float_val=query,\n",
    "        )\n",
    "        for namespace in filter:\n",
    "            restrict = match_service_pb2.Namespace()\n",
    "            restrict.name = namespace.name\n",
    "            restrict.allow_tokens.extend(namespace.allow_tokens)\n",
    "            restrict.deny_tokens.extend(namespace.deny_tokens)\n",
    "            request.restricts.append(restrict)\n",
    "        b_requests.append(request)\n",
    "\n",
    "    batch_request_for_index.requests.extend(b_requests)\n",
    "    batch_request.requests.append(batch_request_for_index)\n",
    "\n",
    "    # Perform the request\n",
    "    response = stub.BatchMatch(batch_request)\n",
    "\n",
    "    # Wrap the results in MatchNeighbor objects and return\n",
    "    neighbors = [\n",
    "                    [\n",
    "                        MatchNeighbor(id=neighbor.id, distance=neighbor.distance)\n",
    "                        for neighbor in embedding_neighbors.neighbor\n",
    "                    ]\n",
    "                    for embedding_neighbors in response.responses[0].responses\n",
    "                ]\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='310080', distance=18.029903411865234),\n",
       "  MatchNeighbor(id='702494', distance=16.84667205810547),\n",
       "  MatchNeighbor(id='505832', distance=16.334247589111328),\n",
       "  MatchNeighbor(id='825418', distance=16.22643280029297),\n",
       "  MatchNeighbor(id='707954', distance=16.183256149291992),\n",
       "  MatchNeighbor(id='436242', distance=16.11363410949707),\n",
       "  MatchNeighbor(id='955052', distance=16.022321701049805),\n",
       "  MatchNeighbor(id='20414', distance=15.94982624053955),\n",
       "  MatchNeighbor(id='208920', distance=15.804502487182617),\n",
       "  MatchNeighbor(id='380434', distance=15.756570816040039)],\n",
       " [MatchNeighbor(id='752950', distance=21.807270050048828),\n",
       "  MatchNeighbor(id='690062', distance=19.74156951904297),\n",
       "  MatchNeighbor(id='52842', distance=19.29770278930664),\n",
       "  MatchNeighbor(id='484314', distance=18.903165817260742),\n",
       "  MatchNeighbor(id='317160', distance=18.501405715942383),\n",
       "  MatchNeighbor(id='1150802', distance=18.053863525390625),\n",
       "  MatchNeighbor(id='377396', distance=18.051637649536133),\n",
       "  MatchNeighbor(id='47466', distance=17.993053436279297),\n",
       "  MatchNeighbor(id='442226', distance=17.942176818847656),\n",
       "  MatchNeighbor(id='310054', distance=17.931102752685547)],\n",
       " [MatchNeighbor(id='1087282', distance=21.09122085571289),\n",
       "  MatchNeighbor(id='587106', distance=20.418033599853516),\n",
       "  MatchNeighbor(id='1046944', distance=20.412609100341797),\n",
       "  MatchNeighbor(id='187490', distance=20.1966552734375),\n",
       "  MatchNeighbor(id='1018752', distance=19.673538208007812),\n",
       "  MatchNeighbor(id='652860', distance=19.342601776123047),\n",
       "  MatchNeighbor(id='248960', distance=19.085472106933594),\n",
       "  MatchNeighbor(id='278716', distance=18.92349624633789),\n",
       "  MatchNeighbor(id='441754', distance=18.643259048461914),\n",
       "  MatchNeighbor(id='660878', distance=18.465301513671875)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:3].tolist(), [Namespace(\"class\", [\"even\"])])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='899605', distance=20.079139709472656),\n",
       "  MatchNeighbor(id='792161', distance=18.574535369873047),\n",
       "  MatchNeighbor(id='729301', distance=18.31948471069336),\n",
       "  MatchNeighbor(id='1093903', distance=17.839481353759766),\n",
       "  MatchNeighbor(id='296543', distance=16.99886703491211),\n",
       "  MatchNeighbor(id='21495', distance=16.8770694732666),\n",
       "  MatchNeighbor(id='689839', distance=16.852933883666992),\n",
       "  MatchNeighbor(id='518781', distance=16.65009307861328),\n",
       "  MatchNeighbor(id='405251', distance=16.278234481811523),\n",
       "  MatchNeighbor(id='1142011', distance=16.186227798461914)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "A3KYVw5HB-4v",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3 ms ± 245 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "\n",
    "vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, test[:1].tolist(), [Namespace(\"class\", [\"odd\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeUZO3bAGoM-"
   },
   "source": [
    "### Compute Recall\n",
    "\n",
    "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. Note that you can run multiple queries in a single match call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "U9dNIbkEGoM-"
   },
   "outputs": [],
   "source": [
    "# Retrieve nearest neighbors for both the tree-AH index and the brute-force index\n",
    "tree_ah_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_INDEX_ID, NUM_NEIGHBOURS, list(test))\n",
    "\n",
    "brute_force_response_test = vme_grpc_match(ENDPT_IP, DEPLOYED_BRUTE_FORCE_INDEX_ID, NUM_NEIGHBOURS, list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "V-eMF05UGoM-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5787\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute-force option.\n",
    "recalled_neighbors = 0\n",
    "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "    tree_ah_response_test, brute_force_response_test\n",
    "):\n",
    "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "    recalled_neighbors += len(\n",
    "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "    )\n",
    "\n",
    "recall = recalled_neighbors / len(\n",
    "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
    ")\n",
    "\n",
    "print(\"Recall: {}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploy MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/6281238006514843648\n",
      "MatchingEngineIndexEndpoint index_endpoint undeployed. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploying MatchingEngineIndexEndpoint index_endpoint: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Undeploy MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552/operations/3707430819472605184\n",
      "MatchingEngineIndexEndpoint index_endpoint undeployed. Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Deleting MatchingEngineIndexEndpoint : projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n",
      "Delete MatchingEngineIndexEndpoint  backing LRO: projects/1023019892523/locations/us-central1/operations/5434561276569190400\n",
      "MatchingEngineIndexEndpoint deleted. . Resource name: projects/1023019892523/locations/us-central1/indexEndpoints/5679804390207127552\n"
     ]
    }
   ],
   "source": [
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "omj7N9iWv-Tq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting MatchingEngineIndex : projects/896267025569/locations/us-central1/indexes/3778652028759179264\n",
      "Delete MatchingEngineIndex  backing LRO: projects/896267025569/locations/us-central1/indexes/3778652028759179264/operations/3508054176984727552\n",
      "MatchingEngineIndex deleted. . Resource name: projects/896267025569/locations/us-central1/indexes/3778652028759179264\n"
     ]
    }
   ],
   "source": [
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "brute_force_index.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk_matching_engine_for_indexing.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-genai-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3 (genai)",
   "language": "python",
   "name": "conda-env-genai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
